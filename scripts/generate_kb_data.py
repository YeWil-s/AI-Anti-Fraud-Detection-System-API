"""
åè¯ˆçŸ¥è¯†åº“åˆå§‹åŒ–ä¸æ•°æ®å¢å¼ºè„šæœ¬ (å¤§èµ›é«˜åˆ†ç‰ˆ)
1. è¯»å–ç»„å‘˜æ‰‹å·¥æ¸…æ´—çš„ç§å­æ•°æ®é›† (processed_cases.json)
2. è°ƒç”¨ LLM è‡ªåŠ¨æ‰©å†™ 200+ ä¸ªä¸åŒç»´åº¦çš„å˜ä½“è¯æœ¯
3. ç»Ÿä¸€çŒå…¥ ChromaDB å‘é‡æ•°æ®åº“
"""
import sys
import os
import json
import asyncio
from typing import List
from langchain_openai import ChatOpenAI
from langchain.prompts import ChatPromptTemplate
from langchain_core.output_parsers import JsonOutputParser
from pydantic.v1 import BaseModel, Field

# å°†é¡¹ç›®æ ¹ç›®å½•åŠ å…¥ç¯å¢ƒå˜é‡
BASE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
sys.path.append(BASE_DIR)

from app.services.vector_db_service import vector_db
from app.core.logger import get_logger
from app.core.config import settings

logger = get_logger(__name__)

DATA_FILE_PATH = os.path.join(BASE_DIR, "data", "processed_cases.json")

# å¼ºåˆ¶ LLM è¾“å‡ºçš„ç»“æ„
class CaseVariations(BaseModel):
    variations: List[str] = Field(description="ç”Ÿæˆçš„è¯ˆéª—è¯æœ¯å˜ä½“åˆ—è¡¨ï¼ŒåŒ…å«å…·ä½“çš„å¯¹è¯å†…å®¹æˆ–åœºæ™¯æè¿°")

class KnowledgeBaseGenerator:
    def __init__(self):
        self.llm = ChatOpenAI(
            model=settings.LLM_MODEL_NAME,
            temperature=0.7, # ç¨å¾®é«˜ä¸€ç‚¹çš„æ¸©åº¦ï¼Œä¿è¯å˜ä½“çš„å¤šæ ·æ€§
            api_key=settings.LLM_API_KEY,
            base_url=settings.LLM_BASE_URL
        )
        self.output_parser = JsonOutputParser(pydantic_object=CaseVariations)
        
        self.prompt_template = ChatPromptTemplate.from_messages([
            ("system", """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„åè¯ˆæ•°æ®ç”Ÿæˆä¸“å®¶ã€‚
ä½ çš„ä»»åŠ¡æ˜¯æ ¹æ®æä¾›çš„ã€ç§å­æ¡ˆä¾‹ã€‘ï¼Œç”Ÿæˆ {num_variations} ä¸ªè¯¥è¯ˆéª—ç±»å‹çš„ã€å˜ä½“è¯æœ¯ã€‘ã€‚
è¦æ±‚ï¼š
1. å˜ä½“å¿…é¡»è¦†ç›–ä¸åŒçš„å—å®³äººç¾¤ï¼ˆå¦‚è€äººã€å­¦ç”Ÿã€å®å¦ˆï¼‰ã€ä¸åŒçš„æ²Ÿé€šå¹³å°ï¼ˆå¦‚å¾®ä¿¡ã€ç”µè¯ã€çŸ­è§†é¢‘ç›´æ’­é—´ï¼‰ã€‚
2. è¯æœ¯è¦å°½é‡é€¼çœŸï¼Œå£è¯­åŒ–ï¼ŒåŒ…å«è¯±å¯¼è½¬è´¦ã€ä¸‹è½½APPã€ç´¢è¦éªŒè¯ç ç­‰æ ¸å¿ƒè¯ˆéª—è¦ç´ ã€‚
3. å¦‚æœç§å­æ¡ˆä¾‹æ˜¯éŸ³è§†é¢‘ï¼Œè¯·ç”Ÿæˆå¯¹åº”çš„ã€è¯­éŸ³è½¬å†™ã€‘æˆ–ã€è§†é¢‘ç”»é¢æè¿°ã€‘ã€‚
4. ä¸¥æ ¼æŒ‰ç…§ JSON æ ¼å¼è¾“å‡ºåˆ—è¡¨ã€‚

{format_instructions}
"""),
            ("human", "ç§å­æ¡ˆä¾‹ç±»å‹ï¼š{fraud_type}\nç§å­æ¡ˆä¾‹å†…å®¹ï¼š{content}")
        ])

    async def generate_variations(self, fraud_type: str, content: str, num_variations: int = 10) -> List[str]:
        """è°ƒç”¨å¤§æ¨¡å‹ç”Ÿæˆå˜ä½“"""
        try:
            chain = self.prompt_template | self.llm | self.output_parser
            response = await chain.ainvoke({
                "fraud_type": fraud_type,
                "content": content,
                "num_variations": num_variations,
                "format_instructions": self.output_parser.get_format_instructions()
            })
            return response.get("variations", [])
        except Exception as e:
            logger.error(f"ç”Ÿæˆ {fraud_type} å˜ä½“å¤±è´¥: {e}")
            return []

async def init_and_augment_db():
    print("====== å¼€å§‹æ•°æ®å¢å¼ºä¸çŸ¥è¯†åº“åˆå§‹åŒ– ======")
    
    if not os.path.exists(DATA_FILE_PATH):
        logger.error(f"æ‰¾ä¸åˆ°ç§å­æ•°æ®æ–‡ä»¶: {DATA_FILE_PATH}")
        return

    with open(DATA_FILE_PATH, 'r', encoding='utf-8') as f:
        cases = json.load(f)

    if len(cases) < 20:
        logger.warning(f"å½“å‰ç§å­æ¡ˆä¾‹ä»…æœ‰ {len(cases)} ä¸ªï¼")

    generator = KnowledgeBaseGenerator()
    
    all_documents = []
    all_metadatas = []
    all_ids = []
    
    case_counter = 0

    print("ğŸš€ æ­£åœ¨é€šè¿‡å¤§æ¨¡å‹æ‰©å†™æ¡ˆä¾‹ï¼Œè¯·è€å¿ƒç­‰å¾…ï¼ˆå¯èƒ½éœ€è¦å‡ åˆ†é’Ÿï¼‰...")
    
    # 1. éå†ç§å­æ¡ˆä¾‹å¹¶æ‰©å†™
    for seed_case in cases:
        fraud_type = seed_case.get("fraud_type", "æœªçŸ¥")
        modality = seed_case.get("modality", "text")
        content = seed_case.get("content", "")
        
        # å…ˆæŠŠç§å­æ¡ˆä¾‹åŠ è¿›å»
        all_documents.append(content)
        all_metadatas.append({
            "modality": modality,
            "fraud_type": fraud_type,
            "risk_level": seed_case.get("risk_level", "æœªçŸ¥"),
            "source": seed_case.get("source", "åŸå§‹ç§å­")
        })
        all_ids.append(f"case_seed_{case_counter}")
        case_counter += 1

        # é’ˆå¯¹æ¯ä¸ªé»‘æ ·æœ¬ï¼ˆè¯ˆéª—ï¼‰ï¼Œç”Ÿæˆ 10 ä¸ªå˜ä½“
        # å¦‚æœæ˜¯ç™½æ ·æœ¬ï¼ˆå®‰å…¨ï¼‰ï¼Œå¯ä»¥å°‘ç”Ÿæˆå‡ ä¸ªï¼Œæˆ–è€…ä¸ç”Ÿæˆ
        if seed_case.get("risk_level") in ["é«˜å±", "æé«˜å±"]:
            print(f"æ­£åœ¨æ‰©å†™: [{fraud_type}] ...")
            variations = await generator.generate_variations(fraud_type, content, num_variations=10)
            
            for var_content in variations:
                all_documents.append(var_content)
                all_metadatas.append({
                    "modality": modality, # ç»§æ‰¿åŸæ¨¡æ€æè¿°æ–¹å¼
                    "fraud_type": fraud_type,
                    "risk_level": seed_case.get("risk_level", "æœªçŸ¥"),
                    "source": "LLM_Augmented"
                })
                all_ids.append(f"case_var_{case_counter}")
                case_counter += 1

    # 2. çŒå…¥ ChromaDB
    print(f"\nğŸ“¦ æ•°æ®æ‰©å†™å®Œæˆï¼Œå…±å‡†å¤‡å…¥åº“ {len(all_ids)} æ¡æ•°æ®ï¼ˆå«ç§å­ä¸å˜ä½“ï¼‰ã€‚")
    try:
        # è¿™é‡Œå‡è®¾ä½ çš„ vector_db.add_cases æ–¹æ³•æ”¯æŒç›´æ¥æ’å…¥
        vector_db.add_cases(all_documents, all_metadatas, all_ids)
        print("âœ… æˆåŠŸçŒå…¥å‘é‡æ•°æ®åº“ï¼")
    except Exception as e:
        logger.error(f"å†™å…¥å‘é‡åº“å¤±è´¥: {e}", exc_info=True)
        print("âŒ å†™å…¥å¤±è´¥ï¼Œè¯·æ£€æŸ¥æ—¥å¿—ã€‚")

    # 3. æ£€ç´¢æµ‹è¯•
    print("\n====== æ‰§è¡Œ RAG æ£€ç´¢æµ‹è¯• ======")
    test_query = "é¢†å¯¼è®©æˆ‘ç«‹åˆ»ç»™è¿™ä¸ªå¯¹å…¬è´¦æˆ·æ‰“é’±ï¼Œè¯´æœ‰æ€¥ç”¨"
    print(f"æ¨¡æ‹Ÿç”¨æˆ·è¢«éª—è¾“å…¥: '{test_query}'\n")
    
    results = vector_db.search_similar_cases(test_query, n_results=1)
    if results and results.get('documents') and results['documents'][0]:
        print("ã€æ£€ç´¢å‘½ä¸­ã€‘:")
        print(f"- åŒ¹é…æ¡ˆä¾‹: {results['documents'][0][0]}")
        print(f"- è¯ˆéª—ç±»å‹: {results['metadatas'][0][0]['fraud_type']}")
        print(f"- å®˜æ–¹æ•°æ®æº: {results['metadatas'][0][0]['source']}")

if __name__ == "__main__":
    asyncio.run(init_and_augment_db())